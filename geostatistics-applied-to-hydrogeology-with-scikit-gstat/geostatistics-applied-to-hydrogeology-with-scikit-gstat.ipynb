{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "geostatistics-applied-to-hydrogeology-revision1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guiattard/PythonForGeosciences/blob/master/geostatistics-applied-to-hydrogeology-with-scikit-gstat/geostatistics-applied-to-hydrogeology-with-scikit-gstat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9FdunelV_z8"
      },
      "source": [
        "#@title Copyright 2021 Guillaume Attard & Mirko Mälicke { display-mode: \"form\" }\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3dJGa4MV_z1"
      },
      "source": [
        "# Geostatistics applied to hydrogeology with Scikit-GStat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16TJxvD8V_z9"
      },
      "source": [
        "by [Guilllaume Attard](https://guillaumeattard.com/) & [Mirko Mälicke](https://hyd.iwg.kit.edu/english/Staff_788.php) - pythonforgeosciences.com\n",
        "\n",
        "last update 09-07-2021\n",
        "\n",
        "Notebook status : *Final version*\n",
        "\n",
        "## Introduction\n",
        "\n",
        "### Context\n",
        "\n",
        "Spatially continuous data play a significant role in planning, risk assessment and decision making in environmental management [(Li et al. 2011)](https://doi.org/10.1016/j.envsoft.2011.07.004). However, these data are not always available and often difficult or expensive to acquire. The acquisition of environmental data such as groundwater temperature, hydraulic head, substance concentration of soil are usually collected by point sampling. Then, geoscientists often require spatial interpolation methods to get spatially continuous data over a region of interest: here comes the Geostatistics.\n",
        "\n",
        "### What is geostatistics?\n",
        "\n",
        "Geostatistics is a branch of statistics focusing on spatial or spatiotemporal datasets. Developed originally to predict probability distributions of ore grades for mining operations, it is currently applied in diverse disciplines including petroleum geology, hydrogeology, hydrology, meteorology, oceanography, geochemistry, geometallurgy, geography, forestry, environmental control, landscape ecology, soil science, and agriculture ([wikipedia definition](https://en.wikipedia.org/wiki/Geostatistics)).\n",
        "\n",
        "The principle of geostatistic is well resumed on the [documentation webpage](https://mmaelicke.github.io/scikit-gstat/SciKitGStat.pdf): \n",
        ">The basic idea of geostatistics is to describe and estimate spatial correlations in a set of point data. The typical application is geostatistics is an interpolation. Therefore, although using point data, a basic concept is to understand these point data as a sample of a (spatially) continuous variable that can be described as a random field, or to be more precise, a Gaussian random field in many cases. The most fundamental assumption in geostatistics is that any two values xi and xi+h are more similar, the smaller h is, which is a separating distance on the random field. In other words: close observation points will show higher covariances than distant points. In case this most fundamental conceptual assumption does not hold for a specific variable, geostatistics will not be the correct tool to analyze and interpolate this variable.\n",
        "\n",
        "### What we do here\n",
        "\n",
        "The aim of this notebook is to build a piezometric map using the Python Scikit-GStat library and to compare the results with other standard interpolation techniques. After some setups, we will download a dataset of points giving hydraulic head of a groundwater body located in the area of Lyon (France) and we will clean this dataset to eliminate all points outside of our groundwater body of interest.\n",
        "\n",
        "In a second part, we will apply two standard interpolation methods (i.e. linear and cubic) given by the *griddata* function (from *scipy.interpolate*) to map the hydraulic head across our area of interest. The limits of both interpolation methods will be discussed.\n",
        "\n",
        "Finally, we will explore the ordinary kriging method given by the Scikit-GStat library:\n",
        "- We will first build a semi-variogramm exploring different parameters to better understand the relationship between measurements variability and distance between measurements. \n",
        "- Secondly, we will build an ordinary kriging model to interpolate the hydraulic head across our area of interest. \n",
        "- We will finally see how to plot the error estimation across our area of interest.\n",
        "\n",
        "Please note the reference of this library and the full documentation:\n",
        "-  *Mirko Mälicke, Helge David Schneider, Sebastian Müller, & Egil Möller. (2021, April 20).\n",
        "mmaelicke/scikit-gstat: A scipy flavoured geostatistical variogram analysis toolbox (Version v0.5.0). Zenodo. http://doi.org/10.5281/zenodo.4704356*,\n",
        "- the full documentation of this Python library can be downloaded [here](https://mmaelicke.github.io/scikit-gstat/SciKitGStat.pdf).\n",
        "\n",
        "Finally, please note that the name kriging refers to its inventor Dave Krige who published the method in 1951: \n",
        "- *Krige, D. G. (1951). A statistical approach to some basic mine valuation problems on the Witwatersrand. Journal of the Southern African Institute of Mining and Metallurgy, 52(6), 119-139.*\n",
        "\n",
        "## Run me first\n",
        "\n",
        "Two options are proposed to install scikit-gstat. Please select the one you prefer.\n",
        "\n",
        "### Option 1: Install  scikit-gstat with PyPi\n",
        "\n",
        "To run option 1, uncomment and run the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlCg265hV_z_"
      },
      "source": [
        "!pip install scikit-gstat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiqRMehhV_0A"
      },
      "source": [
        "### Option2: Install the most recent version from GitHub\n",
        "\n",
        "To run option 2, please copy/past following instructions into your powershell/terminal:\n",
        "```\n",
        "git clone https://github.com/mmaelicke/scikit-gstat.git\n",
        "cd scikit-gstat\n",
        "pip install -r requirements.txt\n",
        "python setup.py install\n",
        "```\n",
        "\n",
        "### Install/Import other libraries\n",
        "\n",
        "We also need to install and import other libraries as follow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjMD9ZUIWyuv"
      },
      "source": [
        "!apt install gdal-bin python-gdal python3-gdal\n",
        "!pip install fiona shapely pyproj\n",
        "!apt install python3-rtree \n",
        "!pip install git+git://github.com/geopandas/geopandas.git\n",
        "!pip install git+https://github.com/python-visualization/folium\n",
        "!pip install plotly\n",
        "!pip install rasterio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2rEGVZIV_0C"
      },
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import numpy as np\n",
        "\n",
        "# We import the folium library to make interactive maps\n",
        "import folium\n",
        "\n",
        "# We need to import branca.colormap to give pretty colors to our points according \n",
        "# to groundwater table elevation\n",
        "import branca.colormap as cm\n",
        "\n",
        "# We need requests to get our dataset and zipfile to unzip our dataset\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5bEAq5pV_0E"
      },
      "source": [
        "### Import our hydraulic head dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l0BngIsV_0F"
      },
      "source": [
        "The hydraulic head dataset we are working with is available on the github repository of this notebook. Please note that this dataset is derived from a dataset provided by the french geological survey. Please visit a [previous notebook](https://github.com/guiattard/PythonForGeosciences/tree/master/exploring-hydro-geological-data-of-france-with-python) to see how to explore french hydrogeological data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ms9ZGk2V_0F"
      },
      "source": [
        "url = \"https://github.com/guiattard/PythonForGeosciences/raw/master/geostatistics-applied-to-hydrogeology-with-scikit-gstat/hydraulic-head-lyon-sample.zip\"\n",
        "file = \"hydraulic-head-lyon-sample.zip\"\n",
        "# Command to donwload the file at the given url\n",
        "r = requests.get(url)\n",
        "\n",
        "# Then we open the file\n",
        "open(file, 'wb').write(r.content)\n",
        "\n",
        "# We extract the content of the .zip file\n",
        "with zipfile.ZipFile(file, 'r') as unzip: unzip.extractall(\"./dat\")\n",
        "\n",
        "# we finally read the shapefile and make some cleaning\n",
        "gdf = gpd.read_file(\"./dat/hydraulic-head-sample-lyon.shp\")\n",
        "\n",
        "# We rename the hydraulic name column by hh\n",
        "gdf = gdf.rename(columns = {'hydraulic_' : \"hh\"})\n",
        "gdf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngzrl-xuV_0I"
      },
      "source": [
        "We can display the location of our points on a static map using <code>matplotlib</code>:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksQxgrcFV_0J"
      },
      "source": [
        "# We plot the result\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "# We add the location of borehole with hydraulic head\n",
        "gdf.plot(ax = ax, cmap = \"viridis_r\",\n",
        "            column = \"hh\",\n",
        "            markersize=10, \n",
        "            legend = True,\n",
        "            legend_kwds={'label': \"hydraulic head [m a.s.l]\"})\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El5s5jowV_0M"
      },
      "source": [
        "Now, let's display the location of our points on an interactive map using <code>folium</code>. We also add geological tile layers of France using the <code>folium.WmsTileLayer</code> method (please note that we work with longitudes and latitudes with <code>folium</code>):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st0aaVAQV_0O",
        "scrolled": false
      },
      "source": [
        "# We build our map focusing on our site and specifying the zoom start\n",
        "mymap = folium.Map(location=[gdf.lat.mean(), gdf.lon.mean()], \n",
        "                   zoom_start=12,\n",
        "                   show=True, control_scale = True)\n",
        "\n",
        "# Add the geological map of France\n",
        "url = 'http://geoservices.brgm.fr/geologie'\n",
        "layer1 = 'GEOLOGIE'\n",
        "folium.WmsTileLayer(url, layer1, attr = 'BRGM', name = 'Geological map', show=True).add_to(mymap)\n",
        "\n",
        "# Add a feature group to add borehole with hydraulic head measurements\n",
        "fg_gwt = folium.FeatureGroup(name = 'Hydraulic head', show = True)\n",
        "mymap.add_child(fg_gwt)\n",
        "\n",
        "colormap = cm.LinearColormap(colors=['orange', 'yellow', 'green', 'lightblue', 'blue'], \n",
        "                             index=[gdf[\"hh\"].quantile(0.1),\n",
        "                                    gdf[\"hh\"].quantile(0.25),\n",
        "                                    gdf[\"hh\"].quantile(0.5),\n",
        "                                    gdf[\"hh\"].quantile(0.75),\n",
        "                                    gdf[\"hh\"].quantile(0.9)], \n",
        "                             vmin=gdf[\"hh\"].quantile(0.1),\n",
        "                             vmax=gdf[\"hh\"].quantile(0.9))\n",
        "\n",
        "# We add the caption of our colormap\n",
        "colormap.caption = 'Hydraulic head [m asl]'\n",
        "\n",
        "# We add all points of our dataset\n",
        "for i, h in zip(gdf.index.values, gdf.hh.values):\n",
        "    dfi = folium.CircleMarker(\n",
        "        location = [gdf.at[i,'lat'], gdf.at[i,'lon']],\n",
        "        popup =str(round(h,2)) + \" m asl\",\n",
        "        radius= 7,\n",
        "        fill=True,\n",
        "        fill_opacity=0.7,\n",
        "        color = colormap(h),\n",
        "        fill_color = colormap(h))\n",
        "    dfi.add_to(fg_gwt)                \n",
        "\n",
        "mymap.add_child(colormap)\n",
        "mymap.add_child(folium.map.LayerControl(collapsed=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuzdLHML9Iq-"
      },
      "source": [
        "Another good possibility to map the locations is the `plotly` plotting library. One advantage is, that recent versions of `scikit-gstat` can make use of that library to return interactive plots. You can easily switch between plotly and matplotlib as a plotting backend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia_Hto4E9Iq_"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# create the scatter_mapbox\n",
        "fig = px.scatter_mapbox(gdf, \n",
        "    lat='lat', lon='lon', zoom=12, height=450,  \n",
        "    hover_data=['hh', 'depth'], color='hh'\n",
        ")\n",
        "\n",
        "# use a base-style that does not need a MAPBOX token\n",
        "fig.update_layout(\n",
        "    mapbox_style='stamen-terrain',\n",
        "    mapbox=dict(pitch=45),\n",
        ")\n",
        "\n",
        "# get rid of margins\n",
        "fig.update_layout(margin=dict(l=0, r=0, t=0, b=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwFYpN_ZV_0O"
      },
      "source": [
        "### Cleaning our dataset\n",
        "\n",
        "Before any interpolation, we need to clean our dataset. Particularly, we need to exclude all points which are not located in our groundwater body of interest. In this area there are several groundwater bodies and we make the choice to work on the shallow alluvial groundwater body. It includes groundwater flowing through fuvio-glacial corridors (on the eastern part of our available dataset), and groundwater flowing through the modern alluvial deposit.\n",
        "\n",
        "To do so, we need to make a spatial join between our dataset and the shape of our groundwater body. The shape of the relevant groundwater body can be downloaded as follow (please note that provided file is an incomplete shape of the real groundwater body):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDNXCxSBV_0O"
      },
      "source": [
        "url = \"https://github.com/guiattard/PythonForGeosciences/raw/master/geostatistics-applied-to-hydrogeology-with-scikit-gstat/gw-body.zip\"\n",
        "file = \"gw-body.zip\"\n",
        "# Command to donwload the file at the given url\n",
        "r = requests.get(url)\n",
        "\n",
        "# Then we open the file\n",
        "open(file, 'wb').write(r.content)\n",
        "\n",
        "# We extract the content of the .zip file\n",
        "with zipfile.ZipFile(file, 'r') as unzip: unzip.extractall(\"./dat\")\n",
        "\n",
        "# we finally read the shapefile\n",
        "area = gpd.read_file(\"./dat/gw-body.shp\")\n",
        "\n",
        "area.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDJaolH4V_0P"
      },
      "source": [
        "We then make the spatial join and display the location of both files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "173LJ2LAV_0P",
        "scrolled": false
      },
      "source": [
        "# Spatial join\n",
        "gdf = gpd.sjoin(gdf, area, op = \"within\")\n",
        "\n",
        "# PLot the results\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "area.plot(ax = ax, alpha = 0.25)\n",
        "\n",
        "# We add the location of borehole with water level in blue\n",
        "gdf.plot(ax = ax, cmap = \"viridis_r\",\n",
        "            column = \"hh\",\n",
        "            markersize=10, \n",
        "            legend = True,\n",
        "            legend_kwds={'label': \"hydraulic head [m a.s.l]\"})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEFL8hFuV_0Q"
      },
      "source": [
        "We can also display some histograms using the `hist` method and boxplots using the `boxplot` method to have a closer look on how our values (i.e. hydraulic head `hh` and ground elevation `z`) are distributed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "906dksCcV_0Q"
      },
      "source": [
        "fig, axs = plt.subplots(1,3, figsize=(10,4))\n",
        "ax = axs[0:2]\n",
        "gdf[['hh', 'z']].hist(ax = ax, bins=25)\n",
        "\n",
        "ax = axs[2]\n",
        "ax.set_ylabel('hydrualic head [m]')\n",
        "gdf[['hh', 'z']].boxplot(ax = ax)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqEXia4qV_0Q"
      },
      "source": [
        "The hydraulic head boxplot put in evidence a very low outlier (around 130 m). This point can easily be identified in yellow on the previous map, in the south of our area of interest. Considering the very low hydraulic gradient of the groundwater body we are studying (about 0.2\\%) and other measurements around, this value is clearly an error and should be removed from our analysis (or maybe not an error but a hydraulic head measurement inside a pumping well). Then, let's remove points where hydraulic head is lower than 145 m and display our cleaned dataset (please note that we could have gone further to clean this dataset):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJqm_evMV_0R"
      },
      "source": [
        "gdf = gdf[gdf.hh > 145]\n",
        "\n",
        "# PLot the results\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "area.plot(ax = ax, alpha = 0.25)\n",
        "\n",
        "# We add the location of borehole with water level in blue\n",
        "gdf.plot(ax = ax, cmap = \"viridis_r\",\n",
        "            column = \"hh\",\n",
        "            markersize=10, \n",
        "            legend = True,\n",
        "            legend_kwds={'label': \"hydraulic head [m a.s.l]\"})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j76bYK3UV_0X"
      },
      "source": [
        "## Application of two standard interpolation techniques using `griddata`\n",
        "\n",
        "### Creation of a grid over the area of interest\n",
        "\n",
        "First, we need to build a meshgrid over the area of interest. A mesh-grid is a grid of coordinates, in which each value simply holds the indices of the position in the grid. In our case, the meshgrid is two dimensional, therefore the two grid-arrays (for x and y) will hold all coordinates present in the grid. We need to create this grid, as the coordinates are the input data for the `griddata` function. To do so, we need to specify the resolution of the grid we want (the number of values between our x-min and our x-max and similarly in the y-direction) and build the grid using the `numpy.mgrid` method: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO5A7025V_0Y"
      },
      "source": [
        "# We determine xmin, xmax, ymin and ymax from our dataset:\n",
        "xv = gdf['x'].values\n",
        "yv = gdf['y'].values\n",
        "\n",
        "xmin, xmax = min(xv), max(xv)\n",
        "ymin, ymax = min(yv), max(yv)\n",
        "\n",
        "# We determine the resolution in x direction:\n",
        "res_x = 100\n",
        "# We determine the resolution in y direction\n",
        "# based on res_x to make a regular grid:\n",
        "res_y = int((ymax - ymin)*res_x/(xmax - xmin))\n",
        "\n",
        "# We build the grid:\n",
        "xx,yy = np.mgrid[xmin:xmax:complex(res_x), \n",
        "                 ymin:ymax:complex(res_y)]\n",
        "\n",
        "print('X coordinates:\\n', xx[:5,:5].round(1))\n",
        "print('Y coordinates:\\n', yy[:5,:5].round(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj7mM8LuV_0Y"
      },
      "source": [
        "### Linear and cubic interpolations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPpZvwA2V_0Y"
      },
      "source": [
        "Then, we can easily make boths interpolations (linear and cubic) of hydraulic head value on our regular grid by using the `griddata` function from the `scipy` library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjpH7qjBV_0Z"
      },
      "source": [
        "from scipy.interpolate import griddata\n",
        "\n",
        "# We put the x/y coordinates of our dataset into an array\n",
        "points = np.asanyarray(gdf[['x', 'y']])\n",
        "\n",
        "# We put our hydraulic head values of our dataset into list of the same dimension\n",
        "values = gdf['hh'].values\n",
        "\n",
        "# We make the linear interpolation\n",
        "HH_LINEAR = griddata(points, values, (xx, yy), method='linear')\n",
        "\n",
        "# We make the cubic interpolation\n",
        "HH_CUBIC = griddata(points, values, (xx, yy), method='cubic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJCluRi-V_0a"
      },
      "source": [
        "We can now plot the results given by both techniques:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsoxmpgwV_0a"
      },
      "source": [
        "fig, axs = plt.subplots(1,2, figsize=(15, 10), sharey=True)\n",
        "\n",
        "ax =axs[0]\n",
        "# We plot contour fringes based on our linear griddata interpolation\n",
        "ctr_linear = ax.contourf(xx, \n",
        "                         yy, \n",
        "                         HH_LINEAR,\n",
        "                         range(150,200,5),\n",
        "                         cmap = \"viridis_r\", \n",
        "                         alpha = 0.5)\n",
        "\n",
        "# Some parameters to make a pretty fig:\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "plt.colorbar(ctr_linear, cax=cax, label = 'Hydraulic head [m asl]')\n",
        "ax.set_title(\"Interpolation with the linear method\")\n",
        "\n",
        "# We add the location of points of our dataset\n",
        "gdf.plot(ax = ax, c = \"black\", marker= '.', markersize = 2)\n",
        "\n",
        "ax =axs[1]\n",
        "# We plot contour fringes based on our cubic griddata interpolation\n",
        "ctr_cubic = ax.contourf(xx, \n",
        "                        yy, \n",
        "                        HH_CUBIC,\n",
        "                        range(150,200,5),\n",
        "                        cmap = \"viridis_r\",\n",
        "                        alpha = 0.5)\n",
        "\n",
        "# Some parameters to make a pretty fig:\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "plt.colorbar(ctr_cubic, cax=cax, label = 'Hydraulic head [m asl]')\n",
        "\n",
        "ax.set_title(\"Interpolation with the cubic method\")\n",
        "\n",
        "# We add the location of points of our dataset\n",
        "gdf.plot(ax = ax, c = \"black\", marker= '.', markersize = 2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayA-jOqSV_0a"
      },
      "source": [
        "### Limits of standard interpolation techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeH8mKF4V_0b"
      },
      "source": [
        "The previous figure shows that linear and cubic interpolations techniques give very different results. It is explained by the fact that the weight given by neighboring points to estimate a value is of course not the same. According to the `scipy.interpolate.griddata` [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.griddata.html):\n",
        "- the `linear` method tessellates the input point set to N-D simplices, and interpolate linearly on each simplex.\n",
        "- the `cubic` method returns the value determined from a [cubic spline](https://en.wikipedia.org/wiki/Spline_(mathematics).\n",
        "\n",
        "Of course, both techniques can gives pretty good results for dense and regularly spaced datasets, but these conditions barely happen when handling environmental measurements/sampling which are often scattered and non-uniformly distributed. Under such conditions, these techniques have several drawbacks:\n",
        "- the weighted model is completely arbitrary and doest not account for spatial variability of measurements,\n",
        "- we have no idea of the variance/error associated to the interpolation method,\n",
        "- the cubic method trend to emphasis on diverging values (we can easily check that with the multiple circular zones on the figure)\n",
        "- it is not possible to make extrapolations with these methods.\n",
        "- both methods use splines and can therefore be highly influenced by outliers\n",
        "\n",
        "## Application of a geostatistical approach with `scikit-gstat`\n",
        "\n",
        "### Variography study of our dataset\n",
        "\n",
        "The first step of our geostatistical analysis consists in analysis the variability of our mesurements using a variogram. We can now import to tools we are going to work with (if you need a quick recap on main geostatistic concepts, please visit [this video](https://youtu.be/J-IB4_QL7Oc) on YouTube):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6iMaehTV_0b"
      },
      "source": [
        "from skgstat import Variogram, OrdinaryKriging, plotting\n",
        "\n",
        "# to have nicer plots, we switch to plotly backend\n",
        "plotting.backend('plotly')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlvCz_NpV_0b"
      },
      "source": [
        "We can now build our variogram using the `Variogram` function. We need to specify some arguments:\n",
        "- the coordinates zipped into a list of tuples,\n",
        "- the hydraulic head values of our dataset associated to the coordinates we specified earlier,\n",
        "- the `normalize` parameter which is `True` or `False`: used to normalize distances and semi-variances.\n",
        "- the `model` representing the theoretical variogram function to be used to describe the experimental variogram. It can takes the following possibilities: `spherical`, `exponential`, `gaussian `, `cubic`, `stable`, and `matern`,\n",
        "- the `use_nugget` parameter which is `True` or `False`: the nugget represents the intrinsec variability of measurements (occuring even if the distance between measurements is zero). In our case, wa can expect a nugget effect because our hydraulic head measurements are not synchronous and there is of course a seasonal fluctuation of hydraulic head.\n",
        "- the `maxlag` parameter representing the maximal distance used between points to calculate semi-variances.\n",
        "- the `n_lags` parameter representing the number of intervals in which we divide `maxlag` to calculate intermediate semi-variances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUoudLPVV_0c"
      },
      "source": [
        "V = Variogram(list(zip(gdf.x, gdf.y)), \n",
        "              gdf.hh,\n",
        "              normalize = False,\n",
        "              model = \"spherical\",\n",
        "              use_nugget = True,\n",
        "              n_lags=80, \n",
        "              maxlag=1700)\n",
        "\n",
        "fig = V.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3R5G-SO9IrF"
      },
      "source": [
        "This variogram gives us following informations:\n",
        "- at the origin, we observe the nugget effect: this effet is about 2-4m wich is in line with natural hydrualic head fluctuation in our area of interest,\n",
        "- of course when the distance increases, the semivariance increases too,\n",
        "\n",
        "The `Variogram` instance has a `describe` method that can be used to extract some important parameters from the class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WseF762n9IrF"
      },
      "source": [
        "V.describe(flat=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_M3TqPj9IrF"
      },
      "source": [
        "`scikit-gstat` also has a powerful fitting parameterization. You can switch between a still growing set of fitting algorithms, and apply different weighing functions. These can be used to put more weight on shorter lag bins. This can be helpful in cases where outliers at larger distances than the effective range influence the sill. Remember, that a good fit of the theoretical variogram will have a higher impact on the Kriging quality, than on large lags. \n",
        "With `fit_sigma` you can either pass weights, or the name of a weighing function. With `'linear'` the weights of each lag bin will decrease linearly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01bLE3uw9IrF"
      },
      "source": [
        "V.fit_sigma = 'linear'\n",
        "fig1 = V.plot(show=False)\n",
        "fig1.update_layout(title='Linear Weights', width = 1000)\n",
        "\n",
        "V.fit_sigma = 'sqrt'\n",
        "fig2 = V.plot(show=False)\n",
        "fig2.update_layout(title='Sqrt-decrease Weights', width = 1000)\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNc3_uTHV_0c"
      },
      "source": [
        "You can see, that a linear decrease of weights completely under-estimates the sill. But the `fit_sigma='sqrt'` produces a slightly better fit on the first 5 bins. We can of course play with all parameters to find the more appropriate model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXPzC2oLV_0d"
      },
      "source": [
        "### Building our ordinary kriging model\n",
        "\n",
        "Now that we have a fitting model for our variogram, we can build our ordinary kriging model using the `OrdinaryKriging` function of the `scikit-gstat` library. We must specify some parameters such as:\n",
        "- the variogram we want to use,\n",
        "- `min_points`: the minimum number of points we want to take into account to make our calculation,\n",
        "- `max_points`: the maximal number of points we want to take into account to make our calculation,\n",
        "- `mode`: has to be one of `exact` or `estimate`. In `exact` mode (default) the variogram matrix will be calculated from scratch in each iteration.  This gives an exact solution, but it is also slower. In estimate mode, a set of semivariances is pre-calculated and the closest value will be used.  This is significantly faster, but the estimation quality is dependent on the given precision.\n",
        "- `precision`(integer): Only  needed  if `mode=\"estimate\"`. This  is  the  number  of  pre-calculated in-range semivariances. If chosen too low, the estimation will be off, if toohigh the performance gain is limited."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNjXcBJGV_0d"
      },
      "source": [
        "# We build our kriging model:\n",
        "ok =  OrdinaryKriging(V, min_points=2, max_points=10, mode='exact')\n",
        "\n",
        "# We calculate the hydraulic head on our regular grid,\n",
        "# and we make the result in a good shape\n",
        "hh_hat = ok.transform(xx.flatten(), yy.flatten()).reshape(xx.shape)\n",
        "\n",
        "# We calculate the kriging error on our grid:\n",
        "s2 = ok.sigma.reshape(xx.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhCmKbo1V_0f"
      },
      "source": [
        "Now we can display the result of our ordinary kriging estimation and its associated error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAsfz1WvV_0g"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2 ,figsize=(15, 10), sharey=True)\n",
        "\n",
        "ax = axs[0]\n",
        "\n",
        "# Contour fringes of the kriging process:\n",
        "ctr_hh = ax.contourf(xx, yy, hh_hat,\n",
        "                     range(150,200,5),\n",
        "                     cmap = \"viridis_r\", \n",
        "                     alpha = 0.5)\n",
        "\n",
        "ax.set_title(\"Ordinary kriging estimation\")\n",
        "\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "plt.colorbar(ctr_hh, cax=cax, label = 'Hydraulic head [m asl]')\n",
        "\n",
        "# We add the location of points of our dataset\n",
        "gdf.plot(ax = ax, c = \"black\", marker= '.', markersize = 2)\n",
        "\n",
        "ax = axs[1]\n",
        "\n",
        "# Contour fringes of the kriging error:\n",
        "ctr_err = ax.contourf(xx, yy, s2,\n",
        "                      range(0,12,2),\n",
        "                      cmap = \"plasma\",\n",
        "                      alpha = 0.5)\n",
        "ax.set_title(\"Kriging error estimation\")\n",
        "\n",
        "# We add the location of points of our dataset\n",
        "gdf.plot(ax = ax, c = \"black\", marker= '.', markersize = 2)\n",
        "\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "plt.colorbar(ctr_err, cax=cax, label = 'Error [m]')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFUSBPQXV_0g"
      },
      "source": [
        "As we can see:\n",
        "- we are able to make extrapolation with our ordinary kriging model,\n",
        "- the error increase in areas with a lower density of measurements.\n",
        "\n",
        "Now, considering that interpolation/extrapolation has no meaning outside the groundwater body of interest, we can make a mask to display the result on relevant locations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFu-rkb8V_0g"
      },
      "source": [
        "from shapely.geometry import Point\n",
        "\n",
        "# We initiale a mask with 0 everywhere with the similar shape as earlier\n",
        "maskin = xx - xx\n",
        "\n",
        "# In this mask, we assign True if the point is inside the groundwater body\n",
        "# and we assign False if the point is outside the groundwater body\n",
        "for i in range(maskin.shape[0]):\n",
        "    for j in range(maskin.shape[1]):\n",
        "        xi = xx[i][j]\n",
        "        yj = yy[i][j]\n",
        "        if Point(xi, yj).within(area[\"geometry\"][0]):\n",
        "            maskin[i, j] = 0\n",
        "        else:\n",
        "            maskin[i, j] = 1\n",
        "            \n",
        "# We apply our mask to previous calculated arrays:\n",
        "hh_ma = np.ma.masked_array(hh_hat, maskin)\n",
        "s2_ma = np.ma.masked_array(s2, maskin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb2ZMjn6V_0h"
      },
      "source": [
        "We finally display the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNYQIp32V_0h"
      },
      "source": [
        "# We plot the results:\n",
        "fig, axs = plt.subplots(1, 2 ,figsize=(15, 10), sharey=True)\n",
        "\n",
        "ax = axs[0]\n",
        "# Contour fringes of the kriging process:\n",
        "ctr_hh = ax.contourf(xx, yy, hh_ma, range(150, 200, 5),\n",
        "                     cmap = \"viridis_r\", \n",
        "                     alpha = 0.5)\n",
        "\n",
        "ax.set_title(\"Ordinary kriging estimation\")\n",
        "\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "plt.colorbar(ctr_hh, cax=cax, label = 'Hydraulic head [m asl]')\n",
        "\n",
        "# We add the location of points of our dataset\n",
        "gdf.plot(ax = ax, c = \"black\", marker= '.', markersize = 2)\n",
        "\n",
        "ax = axs[1]\n",
        "\n",
        "# Contour fringes of the kriging error:\n",
        "ctr_err = ax.contourf(xx, yy, s2_ma,\n",
        "                      range(0,12,2),\n",
        "                      cmap = \"plasma\",\n",
        "                      alpha = 0.5)\n",
        "\n",
        "ax.set_title(\"Kriging error\")\n",
        "\n",
        "# We add the location of points of our dataset\n",
        "gdf.plot(ax = ax, c = \"black\", marker= '.', markersize = 2)\n",
        "\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "plt.colorbar(ctr_err, cax=cax, label = 'Error [m]')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvAlhSuQV_0j"
      },
      "source": [
        "### Export the result as a shapefile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgRSzTJ4V_0j"
      },
      "source": [
        "Now we may want to export our ordinary kriging estimation as a shapefile. So, let's convert resulting array into a geodataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gihQgI0RV_0j",
        "scrolled": true
      },
      "source": [
        "df_ok = pd.DataFrame({'x': xx.flatten(),\n",
        "                      'y': yy.flatten(),\n",
        "                      'hh_k': hh_ma.flatten(),\n",
        "                      's2': s2_ma.flatten()})\n",
        "\n",
        "# We remove points without values (in the False part of our mask)\n",
        "df_ok = df_ok.dropna()\n",
        "\n",
        "# We transform our df into a geodataframe\n",
        "export = gpd.GeoDataFrame(df_ok, \n",
        "                          geometry=gpd.points_from_xy(df_ok.x, df_ok.y))\n",
        "\n",
        "export.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMpy5dhiV_0k"
      },
      "source": [
        "We can finally save the the shapefile using the `to_file` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDxqL9IvV_0k"
      },
      "source": [
        "export.to_file('my_kriging_export.shp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJdtubmMV_0l"
      },
      "source": [
        "### Export the result as a geoTIFF raster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVN9SpTUV_0l"
      },
      "source": [
        "To export the kriging estimation as a geoTIFF please follow the procedure below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7rR_bWhV_0l"
      },
      "source": [
        "from osgeo import gdal, osr\n",
        "\n",
        "# we determine the pixel size in x and y directions.\n",
        "dx = abs(xmax - xmin)/res_x\n",
        "dy = abs(ymax - ymin)/res_y\n",
        "\n",
        "# we determine paramaters associated to our image\n",
        "# top left x \n",
        "# w-e pixel resolution\n",
        "# rotation, 0 if image is \"north up\"\n",
        "# top left y\n",
        "# n-s pixel resolution\n",
        "params =(xmin - dx/2, dx, 0, ymax + dy/2, 0, -dy)\n",
        "\n",
        "# the name of our geoTIFF\n",
        "tif_name = \"my_kriging_geotiff.tif\"\n",
        "            \n",
        "# Create/Open the raster\n",
        "output_raster = gdal.GetDriverByName('GTiff').Create(tif_name, res_x+1, res_y+1, 1 ,gdal.GDT_Float32)\n",
        "\n",
        "# Specify its coordinates\n",
        "output_raster.SetGeoTransform(params)\n",
        "\n",
        "# Establish its coordinate encoding:\n",
        "srs = osr.SpatialReference() \n",
        "\n",
        "# Our projection system is specified:\n",
        "srs.ImportFromEPSG(2154)                     \n",
        "\n",
        "# Exports the coordinate system to the file\n",
        "output_raster.SetProjection(srs.ExportToWkt()) \n",
        "\n",
        "# Writes my array to the raster after some transformation due to the resulting shape of the kriging:\n",
        "output_raster.GetRasterBand(1).WriteArray(np.transpose(np.flip(hh_hat[::-1]))) \n",
        "output_raster.GetRasterBand(1).SetNoDataValue(0) \n",
        "output_raster.FlushCache()\n",
        "\n",
        "# Uncomment below if you want to preview the result:\n",
        "#import rasterio\n",
        "#src = rasterio.open(tif_name)\n",
        "#plt.imshow(src.read(1), vmin = 150, vmax = 180)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIGe4wAaV_0l"
      },
      "source": [
        "## Few points of discussion\n",
        "\n",
        "In this notebook, we applied an ordinary kriging method to determine the hydraulic head across an area of interest. The results is in great accordance with the regional understanding of groundwater flow systems. However, our dataset is based on non-synchronous measurements leading to a significative variability which does not allow us to describe draw conclusions regarding local flow systems behavior.\n",
        "\n",
        "There are many other geostatistical methods derived from the variography study (e.g. simple kriging, ordinary kriging, universal kriging, co-kriging, etc.)\n",
        "\n",
        "Please note that kriging algorithms can be combine with machine learning and/or deep learning algorithm to improve local estimations: see [Li et al., (2011)](https://doi.org/10.1016/j.envsoft.2011.07.004) and [Li & Heap (2014)](https://doi.org/10.1016/j.envsoft.2013.12.008)."
      ]
    }
  ]
}